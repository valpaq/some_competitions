{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>5 mins 54 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Moscow</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.1.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months and 2 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_vikto_rfrkz9</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.970 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.8 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O_cluster_uptime:         5 mins 54 secs\n",
       "H2O_cluster_timezone:       Europe/Moscow\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.1.3\n",
       "H2O_cluster_version_age:    2 months and 2 days\n",
       "H2O_cluster_name:           H2O_from_python_vikto_rfrkz9\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.970 Gb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  4\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.8 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "ename": "H2OValueError",
     "evalue": "Unknown parameter inflection_point = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mH2OValueError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8c5c58bd5731>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m                                        \u001b[0msmoothing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                                        \u001b[0mnoise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m     \u001b[1;31m# In general, the less data you have the more regularization you need\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                                        seed=1234)\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m titanic_te.train(x=encoded_columns,\n",
      "\u001b[1;32mc:\\users\\vikto\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\h2o\\estimators\\targetencoder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mH2OValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown parameter %s = %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mH2OValueError\u001b[0m: Unknown parameter inflection_point = 3"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init()\n",
    "from h2o.estimators import H2OTargetEncoderEstimator\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "\n",
    "#Import the titanic dataset\n",
    "titanic = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
    "\n",
    "# Set response column as a factor\n",
    "titanic['survived'] = titanic['survived'].asfactor()\n",
    "response='survived'\n",
    "\n",
    "# Split the dataset into train and test\n",
    "train, test = titanic.split_frame(ratios = [.8], seed = 1234)\n",
    "\n",
    "# Choose which columns to encode\n",
    "encoded_columns = [\"home.dest\", \"cabin\", \"embarked\"]\n",
    "\n",
    "# For k_fold strategy we need to provide fold column\n",
    "fold_column = \"kfold_column\"\n",
    "train[fold_column] = train.kfold_column(n_folds=5, seed=seed)\n",
    "\n",
    "# Train a TE model\n",
    "titanic_te = H2OTargetEncoderEstimator(fold_column=fold_column,\n",
    "                                       data_leakage_handling=\"k_fold\",\n",
    "                                       blending=True,\n",
    "                                       inflection_point=3,\n",
    "                                       smoothing=10,\n",
    "                                       noise=0.15,     # In general, the less data you have the more regularization you need\n",
    "                                       seed=seed)\n",
    "\n",
    "titanic_te.train(x=encoded_columns,\n",
    "                 y=response,\n",
    "                 training_frame=train)\n",
    "\n",
    "# New target encoded train and test sets\n",
    "train_te = titanic_te.transform(frame=train, as_training=True)\n",
    "test_te = titanic_te.transform(frame=test, noise=0)\n",
    "\n",
    "gbm_with_te=H2OGradientBoostingEstimator(fold_column=fold_column,\n",
    "                                         model_id=\"gbm_with_te\")\n",
    "\n",
    "# Training is based on training data with early stopping based on xval performance\n",
    "x_with_te = [\"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"cabin_te\", \"embarked_te\", \"home.dest_te\"]\n",
    "gbm_with_te.train(x=x_with_te, y=response, training_frame=train_te)\n",
    "\n",
    "# To prevent overly optimistic results ( overfitting to xval metrics ) metric is computed on yet unseen test split\n",
    "my_gbm_metrics = gbm_with_te.model_performance(test_te)\n",
    "auc_with_te = my_gbm_metrics.auc()\n",
    "\n",
    "# Train a GBM estimator\n",
    "gbm_baseline=H2OGradientBoostingEstimator(fold_column=fold_column,\n",
    "                                          model_id=\"gbm_baseline\")\n",
    "\n",
    "x_baseline = [\"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"cabin\", \"embarked\", \"home.dest\"]\n",
    "gbm_baseline.train(x=x_baseline, y=response, training_frame=train)\n",
    "\n",
    "# Measuring performance on a test split\n",
    "gbm_baseline_metrics = gbm_baseline.model_performance(test)\n",
    "auc_baseline = gbm_baseline_metrics.auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>9 mins 50 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Moscow</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.1.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months and 2 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_vikto_rfrkz9</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.970 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.8 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O_cluster_uptime:         9 mins 50 secs\n",
       "H2O_cluster_timezone:       Europe/Moscow\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.1.3\n",
       "H2O_cluster_version_age:    2 months and 2 days\n",
       "H2O_cluster_name:           H2O_from_python_vikto_rfrkz9\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.970 Gb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  4\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.8 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "ename": "H2OValueError",
     "evalue": "Unknown parameter inflection_point = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mH2OValueError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8c5c58bd5731>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m                                        \u001b[0msmoothing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                                        \u001b[0mnoise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m     \u001b[1;31m# In general, the less data you have the more regularization you need\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                                        seed=1234)\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m titanic_te.train(x=encoded_columns,\n",
      "\u001b[1;32mc:\\users\\vikto\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\h2o\\estimators\\targetencoder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mH2OValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown parameter %s = %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mH2OValueError\u001b[0m: Unknown parameter inflection_point = 3"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init()\n",
    "from h2o.estimators import H2OTargetEncoderEstimator\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "\n",
    "#Import the titanic dataset\n",
    "titanic = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
    "\n",
    "# Set response column as a factor\n",
    "titanic['survived'] = titanic['survived'].asfactor()\n",
    "response='survived'\n",
    "\n",
    "# Split the dataset into train and test\n",
    "train, test = titanic.split_frame(ratios = [.8], seed = 1234)\n",
    "\n",
    "# Choose which columns to encode\n",
    "encoded_columns = [\"home.dest\", \"cabin\", \"embarked\"]\n",
    "\n",
    "# For k_fold strategy we need to provide fold column\n",
    "fold_column = \"kfold_column\"\n",
    "train[fold_column] = train.kfold_column(n_folds=5, seed=1234)\n",
    "\n",
    "# Train a TE model\n",
    "titanic_te = H2OTargetEncoderEstimator(fold_column=fold_column,\n",
    "                                       data_leakage_handling=\"k_fold\",\n",
    "                                       blending=True,\n",
    "                                       inflection_point=3,\n",
    "                                       smoothing=10,\n",
    "                                       noise=0.15,     # In general, the less data you have the more regularization you need\n",
    "                                       seed=1234)\n",
    "\n",
    "titanic_te.train(x=encoded_columns,\n",
    "                 y=response,\n",
    "                 training_frame=train)\n",
    "\n",
    "# New target encoded train and test sets\n",
    "train_te = titanic_te.transform(frame=train, as_training=True)\n",
    "test_te = titanic_te.transform(frame=test, noise=0)\n",
    "\n",
    "gbm_with_te=H2OGradientBoostingEstimator(fold_column=fold_column,\n",
    "                                         model_id=\"gbm_with_te\")\n",
    "\n",
    "# Training is based on training data with early stopping based on xval performance\n",
    "x_with_te = [\"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"cabin_te\", \"embarked_te\", \"home.dest_te\"]\n",
    "gbm_with_te.train(x=x_with_te, y=response, training_frame=train_te)\n",
    "\n",
    "# To prevent overly optimistic results ( overfitting to xval metrics ) metric is computed on yet unseen test split\n",
    "my_gbm_metrics = gbm_with_te.model_performance(test_te)\n",
    "auc_with_te = my_gbm_metrics.auc()\n",
    "\n",
    "# Train a GBM estimator\n",
    "gbm_baseline=H2OGradientBoostingEstimator(fold_column=fold_column,\n",
    "                                          model_id=\"gbm_baseline\")\n",
    "\n",
    "x_baseline = [\"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"cabin\", \"embarked\", \"home.dest\"]\n",
    "gbm_baseline.train(x=x_baseline, y=response, training_frame=train)\n",
    "\n",
    "# Measuring performance on a test split\n",
    "gbm_baseline_metrics = gbm_baseline.model_performance(test)\n",
    "auc_baseline = gbm_baseline_metrics.auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
